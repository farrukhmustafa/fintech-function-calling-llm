---
apiVersion: v1
kind: ConfigMap
metadata:
  name: training-config-qlora-optimized
  namespace: mlflow
data:
  axolotl_config.yaml: |
    # Optimized Axolotl configuration for QLoRA training
    # Improvements: Better hyperparameters, more LoRA targets, optimized scheduler
    base_model: Qwen/Qwen2.5-7B-Instruct
    model_type: AutoModelForCausalLM
    tokenizer_type: AutoTokenizer
    trust_remote_code: true
    
    # Dataset
    datasets:
      - path: Team-ACE/ToolACE
        type: chat_template
        chat_template: chatml
        field_messages: conversations
        message_field_role: from
        message_field_content: value
    
    # Training settings
    sequence_len: 2048
    sample_packing: true
    pad_to_sequence_len: true
    
    # Optimized QLoRA configuration
    adapter: qlora
    lora_r: 128  # Increased from 64 for more capacity
    lora_alpha: 256  # 2x lora_r for better scaling
    lora_dropout: 0.1  # Slightly higher for regularization
    lora_target_linear: true
    
    # Target ALL linear layers for better coverage
    lora_target_modules:
      - q_proj
      - k_proj
      - v_proj
      - o_proj
      - gate_proj
      - up_proj
      - down_proj
    
    # Quantization
    load_in_4bit: true
    bnb_4bit_quant_type: nf4
    bnb_4bit_compute_dtype: bfloat16
    bnb_4bit_use_double_quant: true
    
    # Optimizations
    flash_attention: true
    bf16: true
    tf32: true
    gradient_checkpointing: true
    
    # Optimized Hyperparameters
    num_epochs: 5  # Increased from 3 for better convergence
    micro_batch_size: 1  # Reduced to fit larger LoRA rank
    gradient_accumulation_steps: 16  # Increased to maintain effective batch size
    learning_rate: 1.5e-4  # Reduced from 2e-4 for stability
    lr_scheduler: cosine
    warmup_ratio: 0.15  # Increased warmup for stability
    weight_decay: 0.05  # Increased for better regularization
    max_grad_norm: 0.5  # Added gradient clipping
    
    # Optimizer improvements
    optimizer: adamw_torch_fused  # Faster than default
    adam_beta1: 0.9
    adam_beta2: 0.999
    adam_epsilon: 1.0e-8
    
    # Evaluation
    val_set_size: 0.05
    eval_steps: 50  # More frequent evaluation
    save_steps: 50  # More frequent checkpointing
    logging_steps: 5
    
    # Early stopping
    early_stopping_patience: 5
    
    # Output
    output_dir: /mnt/data/outputs/qlora-optimized-qwen25-7b
    
    # MLflow integration
    use_mlflow: true

---
apiVersion: batch/v1
kind: Job
metadata:
  name: training-qlora-optimized
  namespace: mlflow
  labels:
    job-type: training
    method: qlora-optimized
spec:
  backoffLimit: 1
  ttlSecondsAfterFinished: 86400
  template:
    metadata:
      labels:
        job: training
        method: qlora-optimized
    spec:
      restartPolicy: Never
      
      nodeSelector:
        library-solution: k8s-training
      
      tolerations:
      - key: nvidia.com/gpu
        operator: Exists
        effect: NoSchedule
      
      containers:
      - name: training
        image: pytorch/pytorch:2.5.1-cuda12.1-cudnn9-devel
        
        command:
        - /bin/bash
        - -c
        - |
          set -ex
          
          export MLFLOW_TRACKING_URI=http://mlflow-server.mlflow.svc.cluster.local:5000
          export MLFLOW_EXPERIMENT_NAME=fintech-function-calling
          export DEBIAN_FRONTEND=noninteractive
          
          echo "Installing system dependencies..."
          apt-get update && apt-get install -y git build-essential
          
          echo "Installing Axolotl from PyPI..."
          pip install packaging setuptools wheel ninja
          pip install --no-build-isolation 'axolotl[flash-attn,deepspeed]'
          
          echo "Installing mlflow..."
          pip install mlflow
          
          mkdir -p /root/.triton/autotune
          mkdir -p /workspace
          cd /workspace
          
          cp /config/axolotl_config.yaml ./axolotl_config.yaml
          mkdir -p /mnt/data/outputs
          
          echo "Starting Optimized QLoRA training..."
          echo "MLflow URI: $MLFLOW_TRACKING_URI"
          echo "Improvements: Higher rank (128), more targets, 5 epochs, better scheduler"
          
          accelerate launch -m axolotl.cli.train axolotl_config.yaml
          
          echo "Optimized training completed!"
          
          if [ -d "/mnt/data/outputs/qlora-optimized-qwen25-7b" ]; then
            echo "Model saved to /mnt/data/outputs/qlora-optimized-qwen25-7b"
          fi
        
        env:
        - name: MLFLOW_TRACKING_URI
          value: "http://mlflow-server.mlflow.svc.cluster.local:5000"
        - name: MLFLOW_EXPERIMENT_NAME
          value: "fintech-function-calling"
        - name: HF_TOKEN
          valueFrom:
            secretKeyRef:
              name: huggingface-secret
              key: token
              optional: true
        - name: CUDA_VISIBLE_DEVICES
          value: "0"
        
        resources:
          requests:
            nvidia.com/gpu: 1
            cpu: 8
            memory: 100Gi
          limits:
            nvidia.com/gpu: 1
            cpu: 16
            memory: 200Gi
        
        volumeMounts:
        - name: config
          mountPath: /config
        - name: data
          mountPath: /mnt/data
        - name: workspace
          mountPath: /workspace
        - name: huggingface-cache
          mountPath: /root/.cache/huggingface
      
      volumes:
      - name: config
        configMap:
          name: training-config-qlora-optimized
      - name: data
        hostPath:
          path: /mnt/data
          type: DirectoryOrCreate
      - name: workspace
        emptyDir: {}
      - name: huggingface-cache
        emptyDir: {}

